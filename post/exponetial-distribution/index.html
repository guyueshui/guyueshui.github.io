<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>Exponential Distribution - 水阙</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="Yychi"><meta name=description content="Story The Exponential distribution is the continuous counterpart to the Geometric distribution. The story of the Exponential distribution is analogous, but we are now waiting for a success in continuous time, where successes arrive at a rate of $\lambda$ successes per unit of time. The average number of successes in a time interval of length $t$ is $\lambda t$, though the actual number of successes varies randomly. An Exponential random variable represents the waiting time until the first arrival of a success."><meta name=keywords content="水阙,yychi"><meta name=generator content="Hugo 0.117.0 with theme even"><link rel=canonical href=https://guyueshui.github.io/post/exponetial-distribution/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<link href=/sass/main.min.4db6eefa019323deeb0f96ac97b0195c6875d5cb6a98e30c1e245d54b43d54bc.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><link rel=stylesheet href=/css/even-custom.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&family=Noto+Serif+SC:wght@400;500;700&display=swap" rel=stylesheet><meta property="og:title" content="Exponential Distribution"><meta property="og:description" content="Story The Exponential distribution is the continuous counterpart to the Geometric distribution. The story of the Exponential distribution is analogous, but we are now waiting for a success in continuous time, where successes arrive at a rate of $\lambda$ successes per unit of time. The average number of successes in a time interval of length $t$ is $\lambda t$, though the actual number of successes varies randomly. An Exponential random variable represents the waiting time until the first arrival of a success."><meta property="og:type" content="article"><meta property="og:url" content="https://guyueshui.github.io/post/exponetial-distribution/"><meta property="article:section" content="post"><meta property="article:published_time" content="2018-12-25T22:21:49+00:00"><meta property="article:modified_time" content="2019-08-25T00:00:00+00:00"><meta itemprop=name content="Exponential Distribution"><meta itemprop=description content="Story The Exponential distribution is the continuous counterpart to the Geometric distribution. The story of the Exponential distribution is analogous, but we are now waiting for a success in continuous time, where successes arrive at a rate of $\lambda$ successes per unit of time. The average number of successes in a time interval of length $t$ is $\lambda t$, though the actual number of successes varies randomly. An Exponential random variable represents the waiting time until the first arrival of a success."><meta itemprop=datePublished content="2018-12-25T22:21:49+00:00"><meta itemprop=dateModified content="2019-08-25T00:00:00+00:00"><meta itemprop=wordCount content="1080"><meta itemprop=keywords content="math,probability,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Exponential Distribution"><meta name=twitter:description content="Story The Exponential distribution is the continuous counterpart to the Geometric distribution. The story of the Exponential distribution is analogous, but we are now waiting for a success in continuous time, where successes arrive at a rate of $\lambda$ successes per unit of time. The average number of successes in a time interval of length $t$ is $\lambda t$, though the actual number of successes varies randomly. An Exponential random variable represents the waiting time until the first arrival of a success."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Yychi's Blog</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/search/><li class=mobile-menu-item>Search</li></a><a href=/links/><li class=mobile-menu-item>More</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tricks/><li class=mobile-menu-item>Tricks</li></a><a href=/sketch/><li class=mobile-menu-item>Sketch</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Yychi's Blog</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/search/>Search</a></li><li class=menu-item><a class=menu-item-link href=/links/>More</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tricks/>Tricks</a></li><li class=menu-item><a class=menu-item-link href=/sketch/>Sketch</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Exponential Distribution</h1><div class=post-meta><span class=post-time>December 25, 2018</span><div class=post-category><a href=/categories/notes/>Notes</a></div><span id=busuanzi_container_page_pv class=more-meta><span id=busuanzi_value_page_pv><img src=/img/spinner.svg alt=spinner.svg></span> times read</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#story>Story</a></li><li><a href=#basic>Basic</a></li><li><a href=#memeoryless-property>Memeoryless Property</a></li><li><a href=#examples>Examples</a></li></ul></nav></div></div><div class=post-content><h2 id=story>Story</h2><blockquote><p>The Exponential distribution is the continuous counterpart to the <a href=file://./Geometric-Distribution.md>Geometric distribution</a>. The story of the Exponential distribution is analogous, but we are now waiting for a success in continuous time, where successes arrive at a rate of $\lambda$ successes per unit of time. The average number of successes in a time interval of length $t$ is $\lambda t$, though the actual number of successes varies randomly. An Exponential random variable represents the waiting time until the first arrival of a success.</p><div style=text-align:right>——adapted from Book BH</div></blockquote><h2 id=basic>Basic</h2><p><strong>Definition</strong>: A continuous r.v. $X$ is said to have the <em>Exponential distribution</em> with parameter $\lambda$ if its PDF is
$$
f(x) = \lambda e^{-\lambda x}, \quad x > 0
$$
The corresponding CDF is</p><p>$$
F(x) = 1 - e^{-\lambda x}, \quad x > 0
$$</p><p>To calculate the expectation and variance, we first consider $X \sim Exp(1)$ with PDF $f(x) = e^{-x}$, then</p><p>$$
\begin{split}
E(X) &= \int_0^{\infty} x e^{-x} dx = 1 \newline
E(X^2) &= \int_0^{\infty} x^2 e^{-x} dx \newline
&= -x^2e^{-x}|_0^{\infty} + 2\int_0^{\infty} x e^{-x} dx \newline
&= 2E(X) = 2 \newline
Var(X) &= E(X^2) - E^2(X) = 2-1 = 1 \newline
M_X(t) &= E(e^{tX}) = \int_0^{\infty} e^{tx} e^{-x} dx \newline
&= \int_0^{\infty} e^{-(1-t)x} dx = \frac{1}{1-t} \quad \text{for }t&lt;1
\end{split}
$$</p><p>Now let $Y=\frac{X}{\lambda} \sim Exp(\lambda)$ for</p><p>$$
f_Y(y) = f_X(X(y))\frac{dx}{dy} = e^{-\lambda y}\cdot\lambda \sim Exp(\lambda)
$$</p><p>or</p><p>$$
P(Y\le y) = P(X\le \lambda y) = 1 - e^{-\lambda y} \sim Exp(\lambda).
$$</p><p>Hence, we can get</p><ul><li>$E(Y) = E(X/\lambda) = 1/\lambda$</li><li>$Var(Y) = Var(X/\lambda) = 1/\lambda^2$</li><li>MGF (moment generating function):</li></ul><p>$$
\begin{split}
M_Y(t) &= E(e^{tY}) =E(e^{tX/\lambda}) \newline
&= E(e^{\frac{t}{\lambda}X}) = M_X(\frac{t}{\lambda}) = \frac{1}{1-t/\lambda} \newline
&= \frac{\lambda}{\lambda -t} \quad \text{for }t&lt;\lambda
\end{split}
$$</p><h2 id=memeoryless-property>Memeoryless Property</h2><p>Memoryless is something like $P(X \ge s+t ~|~ X \ge s) = P(X \ge t)$, let $X \sim Exp(\lambda)$, then</p><p>$$
\begin{split}
P(X \ge s+t ~|~ X \ge s) &= \frac{P(X \ge s+t, ~X \ge s)}{P(X \ge s)} \newline
&= \frac{P(X \ge s+t)}{P(X \ge s)} \newline
&= \frac{e^{-\lambda (s+t)}}{e^{-\lambda s}} = e^{-\lambda t} \newline
&= P(X \ge t)
\end{split}
$$</p><p><strong>Theorem</strong>: If $X$ is a positive continuous r.v. with memoryless property, then $X$ has an <em>exponential distribution</em>. Similarly, if $X$ is discrete, then it has a <em>geometric distribution</em>.</p><blockquote><p>Proof idea: use survival function and solve differential equations.</p></blockquote><h2 id=examples>Examples</h2><p><strong>eg.1</strong> $X_1 \sim Exp(\lambda_1), ~X_2 \sim Exp(\lambda_2)$, and $X_1 \perp X_2$. Then $P(X_1 &lt; X_2) = \frac{\lambda_1}{\lambda_1 + \lambda_2}$.</p><p><strong>Proof</strong>: By LOTP (law of total probability),</p><p>$$
\begin{split}
P(X_1 &lt; X_2) &= \int_0^{\infty} f_{X_1}(x) P(X_2 > X_1 ~|~ X_1=x) dx \newline
&= \int_0^{\infty} f_{X_1}(x) P(X_2 > x ~|~ X_1=x) dx \newline
&= \int_0^{\infty} f_{X_1}(x) P(X_2 > x) dx \quad \text{(independence)} \newline
&= \int_0^{\infty} \lambda_1 e^{-\lambda_1 x} e^{-\lambda_2 x} dx \newline
&= \lambda_1 \int_0^{\infty} e^{-(\lambda_1 + \lambda_2) x} dx \newline
&= \frac{\lambda_1}{\lambda_1 + \lambda_2}
\end{split}
$$</p><p><strong>eg.2</strong> $\{X_i\}_{i=1}^n$ are independent with $X_j \sim Exp(\lambda_j)$. Let $L = \min(X_1, \cdots, X_n)$, then $L \sim Exp(\lambda_1 + \cdots \lambda_n)$.</p><p><strong>Proof</strong>:</p><p>$$
\begin{split}
P(L > t) &= P\left(\min(X_1,\cdots,X_n) > t\right) \newline
&= P(X_1 > t, \cdots, X_n >t) \newline
&= P(X_1 > t) \cdots P(X_n >t) \quad \text{indep.} \newline
&= e^{-\lambda_1 t}\cdots e^{-\lambda_n t} \newline
&= e^{-(\lambda_1 + \cdots \lambda_n)t} \sim Exp\left(\sum_j \lambda_j\right)
\end{split}
$$</p><p>The intuition of this result is that if you consider $n$ Poisson processes with rate $\lambda_j$,</p><ul><li>$X_1$ as the waiting time for a green car</li><li>$X_2$ as the waiting time for a red car</li><li>&mldr;</li></ul><p>Then $L$ is the waiting time for a car of any color (i.e., any car). So it makes sense, the rate is $\lambda_1 + \cdots + \lambda_n$.</p><p><strong>eg.3</strong> (Difference of two exponetial) Let $X \sim Exp(\lambda)$ and $Y \sim Exp(\mu)$, $X \perp Y$. Then what is the PDF of $Z=X-Y$?</p><p><strong>Solution</strong>:
Recall the story of exponential, one can think of $X$ and $Y$ as waiting times for two independent things. For example,</p><ul><li>$X$ as the waiting time for a red car passing by</li><li>$Y$ as the waiting time for a blue car</li></ul><p>If we see a blue car passing by, then the further waiting time for a red car is still distributed as same distribution as $Y$, for the memoryless property of exponential. Likewise, if we see a red car passing by, then the further waiting time is distributed as same as $X$. The further waiting time is somehow what we are interested in, say $Z$.</p><p>The above intuition says that, the conditional distribution of $X-Y$ given $X > Y$ is the distribution of $X$, and the conditional distribution of $X-Y$ given $X \le Y$ is the distribution of $-Y$ (or in other words, the conditional distribution of $Y-X$ given $Y \ge X$ is same as the distribution of $Y$).</p><blockquote><p>To make full use of our intuition, we know that</p><ul><li><p>If $X>Y$, which means $Z>0$, then $Z~|~X>Y = X$ a.s. holds, that is
$$
\begin{gathered}
f_Z(z~|~X>Y) = \lambda e^{-\lambda z} \newline
\text{and since }P(X&lt;Y) = 0 \newline
\implies f_Z(z) = f_Z(z~|~X>Y)P(X>Y) \newline
= \frac{\mu}{\lambda + \mu}\lambda e^{-\lambda z}.
\end{gathered}
$$</p></li><li><p>If $X &lt; Y$, which means $Z &lt; 0$, then $Z~|~X&lt;Y = -Y$ a.s. holds, that is
$$
\begin{gathered}
f_Z(z~|~X&lt;Y) = f_Y(y(z))\left|\frac{dy}{dz}\right| = \mu e^{\mu z} \newline
\implies f_Z(z) = f_Z(z~|~X&lt;Y)P(X&lt;Y) \
= \frac{\lambda}{\lambda + \mu} \mu e^{\mu z}
\end{gathered}
$$</p></li></ul><p>However, this is just a sketch. Later we will see how to derivate the form mathematically.</p></blockquote><p>From the above point of view, the PDF of $Z$ had better be discussed by the sign of $Z$.</p><ul><li>If $Z > 0$, which implies $X > Y\implies P(X > Y) = 0 $, then</li></ul><p>$$
\begin{split}
P(Z > z) &= P(X-Y>z ~|~ X>Y)P(X>Y) + P(Z>z~|~X&lt;Y)P(X&lt;Y) \newline
&= P(X>z)P(X>Y) + 0 \quad \text{(memoryless)} \newline
&= \frac{\mu}{\lambda + \mu} e^{-\lambda z} \quad \text{(by eg.1)} \newline
\implies f_Z(z) &= \frac{\lambda\mu}{\lambda + \mu} e^{-\lambda z} \quad \text{for }z>0
\end{split}
$$</p><ul><li>If $Z \le 0$, which implies $X \le Y$, then</li></ul><p>$$
\begin{split}
P(Z &lt; z) &= P(Z&lt;z ~|~ X>Y)P(X>Y) + P(X-Y&lt;z~|~X&lt;Y)P(X&lt;Y) \newline
&= 0 + P(Y-X > -z ~|~ Y>X)P(Y>X) \newline
&= P(Y>X)P(Y > -z) \quad \text{(memoryless)} \newline
&= \frac{\lambda}{\lambda + \mu}e^{\mu z} \quad \text{(by eg.1)} \newline
\implies f_Z(z) &= \frac{\lambda\mu}{\lambda + \mu}e^{\mu z} \quad \text{for }z&lt;0
\end{split}
$$</p><p>Therefore, the PDF of $Z$ has the form</p><p>$$
f_Z(z) = \frac{\lambda\mu}{\lambda + \mu}
\begin{cases}
e^{-\lambda z} &\quad z>0 \newline
e^{\mu z} &\quad z&lt;0
\end{cases}
$$</p><blockquote><p>Note: $P(X=Y)=0$ since the integral domain is a line ($y=x$) whose measure is 0. That is $P(Z=0) = 0$. This is why we can give no care of the case $X=Y$.</p></blockquote></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Yychi</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>August 25, 2019</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/math/>math</a>
<a href=/tags/probability/>probability</a></div><nav class=post-nav><a class=prev href=/post/use-reference-in-beamer/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">在 Beamer 中使用参考文献</span>
<span class="prev-text nav-mobile">Prev</span></a>
<a class=next href=/post/%E4%B8%80%E4%BA%9B%E6%8E%A8%E5%AF%BC/><span class="next-text nav-default">常用结论的证明记录</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://giscus.app/client.js data-repo=guyueshui/guyueshui.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkxNDI4MTY5NTE=" data-category=Ideas data-category-id=DIC_kwDOCIM2t84CW4nN data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:guyueshui002@gmail.com class="iconfont icon-email" title=email></a>
<a href=https://github.com/guyueshui class="iconfont icon-github" title=github></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span><div class=busuanzi-footer></div><span class=copyright-year>&copy;
2018 -
2023<span class=heart><i class="iconfont icon-heart"></i></span><span>Yychi</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>