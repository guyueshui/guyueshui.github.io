<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>最大熵对应的概率分布 - 水阙</title>
<meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="Yychi"><meta name=description content="最大熵定理 设 $X \sim p(x)$ 是一个连续型随机变量，其微分熵定义为 $$ h(X) = - \int p(x)\log p(x) dx $$ 其中，$\log$ 一般取自然对数 $\ln$, 单位为 奈特（nats）。 考虑如下优"><meta name=keywords content="水阙,yychi"><meta name=generator content="Hugo 0.127.0 with theme even"><link rel=canonical href=https://guyueshui.github.io/post/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%AF%B9%E5%BA%94%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><link href=/sass/main.min.4db6eefa019323deeb0f96ac97b0195c6875d5cb6a98e30c1e245d54b43d54bc.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><link rel=stylesheet href=/css/even-custom.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&family=Noto+Serif+SC:wght@400;500;700&display=swap" rel=stylesheet><meta property="og:url" content="https://guyueshui.github.io/post/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%AF%B9%E5%BA%94%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/"><meta property="og:site_name" content="水阙"><meta property="og:title" content="最大熵对应的概率分布"><meta property="og:description" content="最大熵定理 设 $X \sim p(x)$ 是一个连续型随机变量，其微分熵定义为 $$ h(X) = - \int p(x)\log p(x) dx $$ 其中，$\log$ 一般取自然对数 $\ln$, 单位为 奈特（nats）。 考虑如下优"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2018-08-01T18:02:36+00:00"><meta property="article:modified_time" content="2019-08-25T00:00:00+00:00"><meta property="article:tag" content="Math"><meta itemprop=name content="最大熵对应的概率分布"><meta itemprop=description content="最大熵定理 设 $X \sim p(x)$ 是一个连续型随机变量，其微分熵定义为 $$ h(X) = - \int p(x)\log p(x) dx $$ 其中，$\log$ 一般取自然对数 $\ln$, 单位为 奈特（nats）。 考虑如下优"><meta itemprop=datePublished content="2018-08-01T18:02:36+00:00"><meta itemprop=dateModified content="2019-08-25T00:00:00+00:00"><meta itemprop=wordCount content="875"><meta itemprop=keywords content="Math"><meta name=twitter:card content="summary"><meta name=twitter:title content="最大熵对应的概率分布"><meta name=twitter:description content="最大熵定理 设 $X \sim p(x)$ 是一个连续型随机变量，其微分熵定义为 $$ h(X) = - \int p(x)\log p(x) dx $$ 其中，$\log$ 一般取自然对数 $\ln$, 单位为 奈特（nats）。 考虑如下优"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Yychi's Blog</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/search/><li class=mobile-menu-item>Search</li></a><a href=/links/><li class=mobile-menu-item>More</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/sketch/><li class=mobile-menu-item>Sketch</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Yychi's Blog</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/search/>Search</a></li><li class=menu-item><a class=menu-item-link href=/links/>More</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/sketch/>Sketch</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>最大熵对应的概率分布</h1><div class=post-meta><span class=post-time>August 1, 2018</span><div class=post-category><a href=/categories/notes/>Notes</a></div><span id=busuanzi_container_page_pv class=more-meta><span id=busuanzi_value_page_pv><img src=/img/spinner.svg alt=spinner.svg></span> times read</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#最大熵定理>最大熵定理</a></li><li><a href=#举例>举例</a><ul><li><a href=#1-高斯分布>1. 高斯分布</a></li><li><a href=#2-指数分布>2. 指数分布</a></li><li><a href=#3-均匀分布>3. 均匀分布</a></li><li><a href=#4-几何分布>4. 几何分布</a></li></ul></li></ul></nav></div></div><div class=post-content><h2 id=最大熵定理>最大熵定理</h2><p><em>设 $X \sim p(x)$ 是一个连续型随机变量，其微分熵定义为</em>
$$
h(X) = - \int p(x)\log p(x) dx
$$
<em>其中，$\log$ 一般取自然对数 $\ln$, 单位为 奈特（nats）。</em></p><p>考虑如下优化问题：
$$
\begin{array}{ll}
&\underset{p}{\text{Maximize}} & \displaystyle h(p) = - \int_S p(x)\log p(x) dx \newline
&\text{Subject to} &\displaystyle \int_S p(x) dx = 1 \newline
&~ & p(x) \ge 0 \newline
&~ & \displaystyle \int_S p(x) f_i(x) dx = \alpha_i, ~i=1,2,3,\dots,n
\end{array}
$$
其中，集合 $S$ 是随机变量的 support，即其所有可能的取值。我们意图找到这样的概率分布 $p$, 他满足所有的约束（前两条是概率公理的约束，最后一条叫做矩约束，在模型中有时会假设随机变量的矩为常数），并且能够使得熵最大。将上述优化问题写成标准形式：</p><p>$$
\begin{array}{ll}
&\underset{p}{\text{Minimize}} & \displaystyle \int_S p(x)\log p(x) dx \newline
&\text{Subject to} &-p(x) \le 0 \newline
&~ &\displaystyle \int_S p(x) dx = 1 \newline
&~ & \displaystyle \int_S p(x) f_i(x) dx = \alpha_i, ~i=1,2,3,\dots,n
\end{array}
$$</p><p>使用<a href=https://en.wikipedia.org/wiki/Lagrange_multiplier>Lagrange 乘数法</a>得到其 Lagrangian</p><p>$$
L(p,\boldsymbol{\lambda}) = \int_S p\log p ~dx - \mu_{-1}p + \mu_0 \left(\int_S p ~dx - 1\right) + \sum_{j=1}^n \lambda_j \left(\int_S pf_j~dx - \alpha_j\right)
$$</p><p>根据 KKT 条件对 Lagrangian 求导令为 0，可得最优解。</p><p>$$
\begin{gathered}
\frac{\partial L}{\partial p} = \ln p + 1 - \mu_{-1} + \mu_0 + \sum_{j=1}^n \lambda_jf_j := 0 \newline
\implies p = \exp\left(-1 + \mu_{-1} - \mu_0 - \sum_{j=1}^n \lambda_j f_j \right) =\displaystyle c^{\star} e^{-\sum_{j=1}^n\lambda_j^{*} f_j(x)} := p^{\star}
\end{gathered}
$$</p><p>其中，我们要选择 $c^{\star}$, $\boldsymbol{\lambda}^{\star}$ 使得 $p(x)$ 满足约束。到这里我们知道，在所有满足约束的概率分布当中，$p^{\star}$ 是使得熵达到最大的那一个！</p><hr><h2 id=举例>举例</h2><h3 id=1-高斯分布>1. 高斯分布</h3><p>约束：</p><ul><li>$E(X) = 0 \implies f_1 = x$</li><li>$E(X^2) = \sigma^2 \implies f_2 = x^2$</li></ul><p>根据上面的论证，最大熵分布应具有如下形式：</p><p>$$
p(x) = ce^{-\lambda_1x - \lambda_2 x^2}
$$</p><p>再根据 KKT 条件：</p><ol><li>$\int_{-\infty}^{+\infty} p(x) = 1$</li><li>$\int_{-\infty}^{+\infty} x p(x) = 0$</li><li>$\int x^2 p(x) = \sigma^2$</li></ol><p>由条件 $(2) \implies p(x)$ 是偶函数 $\implies \lambda_1 = 0$, 原条件变成</p><ol><li>$\int_{-\infty}^{+\infty} ce^{-\lambda_2x^2} = 1$</li><li>$\int x^2 ce^{-\lambda_2x^2} = \sigma^2$</li></ol><p>$$
\implies c = \frac{1}{\sqrt{2\pi\sigma^2}}, ~\lambda_2 = \frac{1}{2\sigma^2} \implies p(x) = \frac{1}{\sqrt{2\pi\sigma^2}} e^{-\frac{x^2}{2\sigma^2}} \sim N(0, ~\sigma^2)
$$</p><h3 id=2-指数分布>2. 指数分布</h3><p>约束：</p><ul><li>$X \ge 0$</li><li>$E(X) = \frac{1}{\mu}$</li></ul><p>根据上面的论证，最大熵分布应具有如下形式：</p><p>$$
p(x) = ce^{-\lambda_1x}
$$</p><p>再根据 KKT 条件：</p><ol><li>$\int_{0}^{+\infty} ce^{-\lambda_1x}= 1$</li><li>$\int_0^{+\infty} x ce^{-\lambda_1x} = \frac{1}{\mu}$</li></ol><p>推导如下：</p><p>$$
\begin{gathered}
\int_{0}^{+\infty} e^{-\lambda_1x} = \frac{1}{c} \implies \lambda_1 = c \newline
\int_{0}^{+\infty}x e^{-\lambda_1x} = \frac{1}{c\mu} = \frac{1}{\lambda_1\mu} \implies \lambda_1 = \mu
\end{gathered}
$$</p><p>$\implies p(x) = \mu e^{-\mu x} \sim Exp(\mu)$</p><h3 id=3-均匀分布>3. 均匀分布</h3><p>约束：</p><ul><li>$a \le X \le b$</li></ul><p>根据上面的论证，最大熵分布应具有如下形式：
$$
\begin{gathered}
p(x) = ce^{- 0x} = c \newline
\int_a^b c ~dx = 1 \implies c = \frac{1}{b-a}
\end{gathered}
$$
$\implies p(x) = \frac{1}{b-a} \sim Unif(a,~b)$</p><h3 id=4-几何分布>4. 几何分布</h3><p>几何分布计数直到第一次成功前所有的失败次数。$P(X=k) = q^kp$
约束：</p><ul><li>$X = 0,1,2,\dots$</li><li>$E(X) = \frac{1-p}{p}$</li></ul><p>根据上面的论证，最大熵分布应具有如下形式：</p><p>$$
P(X=k) = p_k = ce^{-\lambda_1 k}
$$</p><p>再根据 KKT 条件：</p><ol><li>$\sum_{k=0}^{\infty} p_k = 1$</li><li>$\sum_{k=0}^{\infty} k p_k = \frac{1-p}{p}$</li></ol><p>推导如下：</p><p>$$
\begin{gathered}
\sum_{k=0}^{\infty} ce^{-\lambda_1 k} = c \sum_{k=0}^{\infty} q^k \quad(\text{where }q = e^{-\lambda_1}) \newline
= \frac{c}{1-q} \implies c = 1-q \newline
\sum_{k=0}^{\infty} k ce^{-\lambda_1 k} = c\sum_{k=1}^{\infty} k (e^{-\lambda_1})^k = c\sum_{k=1}^{\infty}k q^k = cq \sum kq^{k-1} \newline
= cq \sum (q^k)&rsquo; = cq \left(\sum_{k=1}^{\infty}q^k\right)&rsquo; = cq \left(\frac{q}{1-q}\right)&rsquo; \newline
= cq \cdot \frac{1}{(1-q)^2} = \frac{q}{1-q} = \frac{1-p}{p}
\end{gathered}
$$</p><p>$\implies e^{-\lambda_1} = q = 1-p, ~ c =p \implies P(X=k) = p_k = pq^k \sim Geom(p)$</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Yychi</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>August 25, 2019</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/math/>math</a></div><nav class=post-nav><a class=prev href=/post/%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%87%8D%E8%A3%85linux/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">记一次重装 Linux</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/post/%E4%BA%8C%E5%8D%81%E5%9B%9B/><span class="next-text nav-default">二十四</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://giscus.app/client.js data-repo=guyueshui/guyueshui.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkxNDI4MTY5NTE=" data-category=Ideas data-category-id=DIC_kwDOCIM2t84CW4nN data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:guyueshui002@gmail.com class="iconfont icon-email" title=email></a><a href=https://github.com/guyueshui class="iconfont icon-github" title=github></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span><div class=busuanzi-footer></div><span class=copyright-year>&copy;
2018 -
2024<span class=heart><i class="iconfont icon-heart"></i></span><span>Yychi</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script><script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script><script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>