<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Nueral Network Learning Notes - 水阙</title>
<meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="Yychi"><meta name=description content="Hello here.
CNN Conv Layer Conv Layer is usually decreasing the input size, i.e., the output size may less or equal than input.
take a volume as input: height x weight x depth, e.g., 32x32x3. Typically think an image having three channels: R, G, B. a filter has the same depth as the input volume, e.g., 5x5x3 (since the filter always has a same depth as input vloume, the depth of the filter is sometimes omitted). each filter convolving with the input will produce an activation map, two filters will produce two, etc. The result of the convolution at each location is just a scalar number (the result of taking a dot product between the filter and a small chunk of the image, i.e., $5\times 5 \times 3 = 75$-dimensional dot product + bias: $w^\top x + b$), which totally yields a 2D matrix (called activation map) as the filter sliding over the image. For example, 32x32x3 image convolved by 5x5x3 filter will yield a 28x28 activation map.
"><meta name=keywords content="水阙,yychi"><meta name=generator content="Hugo 0.139.2 with theme even"><link rel=canonical href=https://guyueshui.github.io/post/nn-notes/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script><link href=/sass/main.min.4db6eefa019323deeb0f96ac97b0195c6875d5cb6a98e30c1e245d54b43d54bc.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><link rel=stylesheet href=/css/even-custom.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&family=Noto+Serif+SC:wght@400;500;700&display=swap" rel=stylesheet><meta property="og:url" content="https://guyueshui.github.io/post/nn-notes/"><meta property="og:site_name" content="水阙"><meta property="og:title" content="Nueral Network Learning Notes"><meta property="og:description" content="Hello here.
CNN Conv Layer Conv Layer is usually decreasing the input size, i.e., the output size may less or equal than input.
take a volume as input: height x weight x depth, e.g., 32x32x3. Typically think an image having three channels: R, G, B. a filter has the same depth as the input volume, e.g., 5x5x3 (since the filter always has a same depth as input vloume, the depth of the filter is sometimes omitted). each filter convolving with the input will produce an activation map, two filters will produce two, etc. The result of the convolution at each location is just a scalar number (the result of taking a dot product between the filter and a small chunk of the image, i.e., $5\times 5 \times 3 = 75$-dimensional dot product + bias: $w^\top x + b$), which totally yields a 2D matrix (called activation map) as the filter sliding over the image. For example, 32x32x3 image convolved by 5x5x3 filter will yield a 28x28 activation map."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2019-10-29T00:00:00+00:00"><meta property="article:modified_time" content="2024-11-02T17:39:45+08:00"><meta property="article:tag" content="Cnn"><meta itemprop=name content="Nueral Network Learning Notes"><meta itemprop=description content="Hello here.
CNN Conv Layer Conv Layer is usually decreasing the input size, i.e., the output size may less or equal than input.
take a volume as input: height x weight x depth, e.g., 32x32x3. Typically think an image having three channels: R, G, B. a filter has the same depth as the input volume, e.g., 5x5x3 (since the filter always has a same depth as input vloume, the depth of the filter is sometimes omitted). each filter convolving with the input will produce an activation map, two filters will produce two, etc. The result of the convolution at each location is just a scalar number (the result of taking a dot product between the filter and a small chunk of the image, i.e., $5\times 5 \times 3 = 75$-dimensional dot product + bias: $w^\top x + b$), which totally yields a 2D matrix (called activation map) as the filter sliding over the image. For example, 32x32x3 image convolved by 5x5x3 filter will yield a 28x28 activation map."><meta itemprop=datePublished content="2019-10-29T00:00:00+00:00"><meta itemprop=dateModified content="2024-11-02T17:39:45+08:00"><meta itemprop=wordCount content="775"><meta itemprop=keywords content="Cnn"><meta name=twitter:card content="summary"><meta name=twitter:title content="Nueral Network Learning Notes"><meta name=twitter:description content="Hello here.
CNN Conv Layer Conv Layer is usually decreasing the input size, i.e., the output size may less or equal than input.
take a volume as input: height x weight x depth, e.g., 32x32x3. Typically think an image having three channels: R, G, B. a filter has the same depth as the input volume, e.g., 5x5x3 (since the filter always has a same depth as input vloume, the depth of the filter is sometimes omitted). each filter convolving with the input will produce an activation map, two filters will produce two, etc. The result of the convolution at each location is just a scalar number (the result of taking a dot product between the filter and a small chunk of the image, i.e., $5\times 5 \times 3 = 75$-dimensional dot product + bias: $w^\top x + b$), which totally yields a 2D matrix (called activation map) as the filter sliding over the image. For example, 32x32x3 image convolved by 5x5x3 filter will yield a 28x28 activation map."><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Yychi's Blog</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/search/><li class=mobile-menu-item>Search</li></a><a href=/links/><li class=mobile-menu-item>More</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/sketch/><li class=mobile-menu-item>Sketch</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Yychi's Blog</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/search/>Search</a></li><li class=menu-item><a class=menu-item-link href=/links/>More</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/sketch/>Sketch</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Nueral Network Learning Notes</h1><div class=post-meta><span class=post-time>October 29, 2019</span><div class=post-category><a href=/categories/notes/>notes</a></div><span id=busuanzi_container_page_pv class=more-meta><span id=busuanzi_value_page_pv><img src=/img/spinner.svg alt=spinner.svg></span> times read</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#cnn>CNN</a><ul><li><a href=#conv-layer>Conv Layer</a></li><li><a href=#convtranspose-layer>ConvTranspose Layer</a></li><li><a href=#pooling-layer>Pooling Layer</a></li></ul></li><li><a href=#references>References</a></li></ul></nav></div></div><div class=post-content><p>Hello here.</p><h2 id=cnn>CNN</h2><h3 id=conv-layer>Conv Layer</h3><p>Conv Layer is usually decreasing the input size, i.e., the output size may less or equal than input.</p><ul><li>take a volume as input: height x weight x depth, e.g., 32x32x3. Typically think an image having three channels: R, G, B.</li><li>a filter has the same depth as the input volume, e.g., 5x5x3 (since the filter always has a same depth as input vloume, the depth of the filter is sometimes omitted).</li><li>each filter convolving with the input will produce an activation map, two filters will produce two, etc.</li></ul><p>The result of the convolution at each location is just a scalar number (the result of taking a dot product between the filter and a small chunk of the image, i.e., $5\times 5 \times 3 = 75$-dimensional dot product + bias: $w^\top x + b$), which totally yields a 2D matrix (called <strong>activation map</strong>) as the filter sliding over the image. For example, 32x32x3 image convolved by 5x5x3 filter will yield a 28x28 activation map.</p><p>ConvNet is a sequence of convolution layers, interspersed with activation functions.</p><p>Let&rsquo;s find out how the spatial dimensions change (since the depth of input and filter will always match, and then shrinks to 1 in actication map). Suppose we have 7x7 input spatially, 3x3 filter, then we have 5x5 output. If applied with stride 2, then 3x3 output. What about stride 3? Oh, it doesn&rsquo;t fit, you cannot apply 3x3 filter on 7x7 input with stride 3.</p><p>Output size: (N-F)/stride + 1 for NxN input, FxF filter.</p><p>Take padding into account since it&rsquo;s common to zero pad the border. E.g., 7x7 input, 3x3 filter, applied with stride 1, pad with 1 pixel border, what is the output? Oh, it&rsquo;s 7x7 output! In general, common to see CONV layers with stride 1, filters of size FxF, and zero-padding with (F-1)/2, which will <strong>perserve size spatially</strong>.</p><p>Output size: $(N + 2\times padding - F) / stride + 1$.</p><p>Train yourself, 32x32x3 input, 10 5x5 filters with stride 1, pad 2, what is the output volume size? Oh, 32x32x10 output! What is the number of parameters in this layer? Oh, $(5 \times 5 \times 3 + 1) \times 10 = 760$, plus 1 for bias.</p><p>To summarize, the Conv Layer:</p><ul><li>Accepts a volume of size $W_1 \times H_1 \times D_1$</li><li>Requires four hyperparameters:<ul><li>Number of filters K,</li><li>their spatial extent F,</li><li>the stride S,</li><li>the amount of zero padding P.</li></ul></li><li>Produces a volume of size $W_2 \times H_2 \times D_2$ where:<ul><li><font color=#0066ff>$W_2 = (W_1 − F + 2P)/S+1$</font></li><li>$H_2 = (H_1−F+2P)/S+1$ (i.e. width and height are computed equally by symmetry)</li><li>$D_2=K$</li></ul></li><li>With parameter sharing, it introduces $F\cdot F\cdot D_1$ weights per filter, for a total of $(F\cdot F\cdot D_1)\cdot K$ weights and $K$ biases.</li><li>In the output volume, the $d$-th depth slice (of size $W_2 \times H_2$) is the result of performing a valid convolution of the $d$-th filter over the input volume with a stride of $S$, and then offset by $d$-th bias.</li></ul><p>A common setting of the hyperparameters is $F=3,S=1,P=1$. However, there are
common conventions and rules of thumb that motivate these hyperparameters.
$F$ is usually odd, $K$ is usually power of 2 for computation efficiency.</p><h3 id=convtranspose-layer>ConvTranspose Layer</h3><p>ConvTranspose Layer is usually increasing the input size, i.e., the output size is greater or equal than input.</p><p>ConvTranspose is also called transposed convolution, deconvolution, etc.
For convenience, we first summarize, the ConvTanspose layer:</p><ul><li>Accepts a volume of size $W_1 \times H_1 \times D_1$</li><li>Requires four hyperparameters:<ul><li>Number of filters K,</li><li>their spatial extent F,</li><li>the stride S,</li><li>the amount of zero padding P.</li></ul></li><li>Produces a volume of size $W_2 \times H_2 \times D_2$ where:<ul><li><font color=#0066ff>$W_2 = S(W_1 − 1) + F - 2P$</font></li><li>$H_2 = S(H_1−1) + F - 2P$ (i.e. width and height are computed equally by symmetry)</li><li>$D_2=K$</li></ul></li></ul><p>The following isn&rsquo;t that correct.</p><p>Then what on earth does transposed convolution do? In fact, a transposed convolution has an associated convolution with <s>$F \times F$ filter, $1/S$ stride, $(F-P-1)$ padding</s>, here i haven&rsquo;t configured it out. Recall that, the layer requires four parameters while K does not affect the spatial size ($W \times H$).</p><p>So if we have a square input volumn of size $I \time I \times D$, and we pass it into an ConvTranspose Layer with parameter (K, F, S, P), then the output has shape:</p><p>$$
\begin{split}
O &= \frac{I + 2(F-P-1) - F}{1/S} + 1 =
\end{split}
$$</p><h3 id=pooling-layer>Pooling Layer</h3><ul><li>makes the representations smaller and more manageable</li><li>operates over each activation map independently</li></ul><p>Intuition of max pooling: select the neuron whose response is maximal.</p><h2 id=references>References</h2><ol><li><a href="https://www.bilibili.com/video/av71409380/?p=7">cs231n winter 2016</a></li><li><a href=http://cs231n.github.io/convolutional-networks/>cs231n notes</a></li><li><a href=http://deeplearning.net/software/theano_versions/dev/tutorial/conv_arithmetic.html>Convolution arithmetic tutorial</a></li><li><a href=https://github.com/vdumoulin/conv_arithmetic>conv_arithmetic</a></li></ol></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Yychi</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>November 2, 2024
<a href=https://github.com/guyueshui/guyueshui.github.io/commit/d7af47e81b31efab29bd443fde7bf1866780ae35 title="- [fix] hugo v0.135.0规范了frontmatter中date格式 - [add] 一个双拼练习网站">(d7af47e8)</a></span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/cnn/>cnn</a></div><nav class=post-nav><a class=prev href=/post/shell-intro/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">Brief Introduction to Shell Script</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/post/server-develop-preliminaries/><span class="next-text nav-default">服务端开发预备知识</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://giscus.app/client.js data-repo=guyueshui/guyueshui.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkxNDI4MTY5NTE=" data-category=Ideas data-category-id=DIC_kwDOCIM2t84CW4nN data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:guyueshui002@gmail.com class="iconfont icon-email" title=email></a><a href=https://github.com/guyueshui class="iconfont icon-github" title=github></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span><div class=busuanzi-footer></div><span class=copyright-year>&copy;
2018 -
2024<span class=heart><i class="iconfont icon-heart"></i></span><span>Yychi</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script><script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script><script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>