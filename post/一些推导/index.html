<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge,chrome=1"><title>常用结论的证明记录 - 水阙</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=cache-control content="no-transform"><meta http-equiv=cache-control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="Yychi"><meta name=description content="高斯分布的微分熵 $X \sim \mathcal{N}(\mu, \sigma^2)~$，$\displaystyle f(x)=\frac{1}{\sqrt{2\pi\sigma^2}"><meta name=keywords content="水阙,yychi"><meta name=generator content="Hugo 0.117.0 with theme even"><link rel=canonical href=https://guyueshui.github.io/post/%E4%B8%80%E4%BA%9B%E6%8E%A8%E5%AF%BC/><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/manifest.json><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><script async src=//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js></script>
<link href=/sass/main.min.4db6eefa019323deeb0f96ac97b0195c6875d5cb6a98e30c1e245d54b43d54bc.css rel=stylesheet><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin=anonymous><link rel=stylesheet href=/css/even-custom.css><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Noto+Sans+SC:wght@400;500;700&family=Noto+Serif+SC:wght@400;500;700&display=swap" rel=stylesheet><meta property="og:title" content="常用结论的证明记录"><meta property="og:description" content="高斯分布的微分熵 $X \sim \mathcal{N}(\mu, \sigma^2)~$，$\displaystyle f(x)=\frac{1}{\sqrt{2\pi\sigma^2}"><meta property="og:type" content="article"><meta property="og:url" content="https://guyueshui.github.io/post/%E4%B8%80%E4%BA%9B%E6%8E%A8%E5%AF%BC/"><meta property="article:section" content="post"><meta property="article:published_time" content="2018-12-20T19:18:29+00:00"><meta property="article:modified_time" content="2020-05-01T00:00:00+00:00"><meta itemprop=name content="常用结论的证明记录"><meta itemprop=description content="高斯分布的微分熵 $X \sim \mathcal{N}(\mu, \sigma^2)~$，$\displaystyle f(x)=\frac{1}{\sqrt{2\pi\sigma^2}"><meta itemprop=datePublished content="2018-12-20T19:18:29+00:00"><meta itemprop=dateModified content="2020-05-01T00:00:00+00:00"><meta itemprop=wordCount content="597"><meta itemprop=keywords content="math,"><meta name=twitter:card content="summary"><meta name=twitter:title content="常用结论的证明记录"><meta name=twitter:description content="高斯分布的微分熵 $X \sim \mathcal{N}(\mu, \sigma^2)~$，$\displaystyle f(x)=\frac{1}{\sqrt{2\pi\sigma^2}"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Yychi's Blog</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/search/><li class=mobile-menu-item>Search</li></a><a href=/links/><li class=mobile-menu-item>More</li></a><a href=/post/><li class=mobile-menu-item>Archives</li></a><a href=/tricks/><li class=mobile-menu-item>Tricks</li></a><a href=/sketch/><li class=mobile-menu-item>Sketch</li></a><a href=/about/><li class=mobile-menu-item>About</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Yychi's Blog</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/search/>Search</a></li><li class=menu-item><a class=menu-item-link href=/links/>More</a></li><li class=menu-item><a class=menu-item-link href=/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=/tricks/>Tricks</a></li><li class=menu-item><a class=menu-item-link href=/sketch/>Sketch</a></li><li class=menu-item><a class=menu-item-link href=/about/>About</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>常用结论的证明记录</h1><div class=post-meta><span class=post-time>December 20, 2018</span><div class=post-category><a href=/categories/notes/>Notes</a></div><span id=busuanzi_container_page_pv class=more-meta><span id=busuanzi_value_page_pv><img src=/img/spinner.svg alt=spinner.svg></span> times read</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class="post-toc-content always-active"><nav id=TableOfContents><ul><li><a href=#高斯分布的微分熵>高斯分布的微分熵</a></li><li><a href=#概率>概率</a><ul><li><a href=#bounds-on-tail-probabilities>Bounds on tail probabilities</a></li></ul></li><li><a href=#law-of-large-numbers>Law of large numbers</a></li><li><a href=#references>References</a></li></ul></nav></div></div><div class=post-content><h2 id=高斯分布的微分熵>高斯分布的微分熵</h2><p>$X \sim \mathcal{N}(\mu, \sigma^2)~$，$\displaystyle f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$，其微分熵推导过程如下：</p><p>$$
\begin{split}
h(X) &= \int_{-\infty}^{\infty}
\frac{-1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) \cdot
\ln \left[
\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
\right] dx \newline
&= \frac{-1}{\sqrt{2\pi\sigma^2}} \int_{-\infty}^{\infty}
\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)
\cdot
\left(
\ln(2\pi\sigma^2)^{-1/2} - \frac{(x-\mu)^2}{2\sigma^2}
\right) dx \newline
&= \frac{1}{2}\ln(2\pi\sigma^2) \int_{-\infty}^{\infty}
\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) dx \newline
&\quad + \int_{-\infty}^{\infty}
\frac{(x-\mu)^2}{2\sigma^2} \cdot
\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right) dx \newline
&= \frac{1}{2}\ln(2\pi\sigma^2) + \frac{1}{2\sigma^2}E(X-\mu)^2 \newline
&= \frac{1}{2}\ln(2\pi\sigma^2) + \frac{1}{2} = \frac{1}{2}\ln(2\pi e\sigma^2) \qquad\text{(nats)}
\end{split}
$$</p><p>又因为 $H_b(X) = \log_ba \cdot H_a(X)$，于是取 $b=e, ~a=2$
$$
\implies \frac{1 \text{ nat}}{x \text{ bits}} = \ln2 \implies x = \frac{1}{\ln2} = \frac{\log e}{\log2} = \log e \text{ bits}
$$
所以
$$
\frac{1}{2}\ln(2\pi e\sigma^2) \text{ nats} =
\frac{1}{2} \cdot \frac{\log(2\pi e\sigma^2)}{\log e} \cdot \log e \text{ bits} =
\frac{1}{2}\log(2\pi e\sigma^2) \text{ bits}
$$</p><h2 id=概率>概率</h2><h3 id=bounds-on-tail-probabilities>Bounds on tail probabilities</h3><p><strong>Markov&rsquo;s inequality</strong>: For any r.v. $X$ and constant $a > 0$,</p><p>$$
P(|X| \ge a) \le \frac{E|X|}{a}.
$$</p><p>Let $Y = \frac{|X|}{a}$. We need to show that $P(Y\ge 1) \le E(Y)$. Note that</p><p>$$
I(Y \ge 1) \le Y,
$$
since if $I(Y \ge 1) = 0$ then $Y \ge 0$, and if $I(Y \ge 1) = 1$ then $Y \ge 1$ (because the indicator says so). Taking the expectation of both sides, we have Markov’s inequality.</p><p><strong>Chebyshev&rsquo;s inequality</strong>: Let $X$ have mean $\mu$ and variance $\sigma^2$. Then for any $a > 0$,</p><p>$$
P(|X-\mu| \ge a) \le \frac{\sigma^2}{a^2}.
$$</p><p>By Markov&rsquo;s inequality,</p><p>$$
P(|X-\mu|\ge a) = P((X-\mu)^2 \ge a^2) \le \frac{E(X-\mu)^2}{a^2} = \frac{\sigma^2}{a^2}.
$$</p><p><strong>Chernoff inequality</strong>: For any r.v. $X$ and constants $a > 0$ and $t>0$,</p><p>$$
P(X\ge a) \le \frac{E(e^{tX})}{e^{ta}}.
$$</p><p>The transformation $g$ with $g(x) = e^{tx}$ is invertible and strictly increasing. So by Markov&rsquo;s inequality, we have</p><p>$$
P(X\ge a) = P(e^{tX} \ge e^{ta}) \le \frac{E(e^{tX})}{e^{ta}}.
$$</p><h2 id=law-of-large-numbers>Law of large numbers</h2><p>Assume we have i.i.d. $X_1, X_2, X_3, \dots$ with finite mean $\mu$ and finite variance $\sigma^2$. For all positive integers $n$, let</p><p>$$
\bar{X}_n = \frac{X_1 + \cdots + X_n}{n}
$$</p><p>be the sample mean of $X_1$ through $X_n$. The sample mean is itself an r.v., with mean $\mu$ and variance $\sigma^2/n$:</p><p>$$
\begin{split}
E(\bar{X}_n) &= \frac{1}{n} E\left(\sum_{i=1}^n X_i\right) = \frac{1}{n}\sum_{i=1}^n E(X_i) = \mu, \newline
\text{Var}(\bar{X}_n) &= \frac{1}{n^2} \text{Var}\left(\sum_{i=1}^n X_i\right) = \frac{1}{n^2}\sum_{i=1}^n \text{Var}(X_i) = \frac{\sigma^2}{n}.
\end{split}
$$</p><p><strong>Strong law of large numbers</strong> The sample mean $\bar{X}_n$ converges to the true mean $\mu$ pointwise as $n \to \infty$, with probability 1. In other words,</p><p>$$
P(\lim_{n\to\infty} \bar{X}_n = \mu) = 1, \text{ or }
\bar{X}_n \overset{a.s.}{\longrightarrow} \mu.
$$</p><p><strong>Weak law of large numbers</strong> For all $\epsilon >0$, $P(|\bar{X}_n-\mu|>\epsilon) \to 0$ as $n\to\infty$. (This is called <em>convergence in probability</em>.) In other words,</p><p>$$
\lim_{n\to\infty}P(\bar{X}_n = \mu) = 1.
$$</p><p>Fix $\epsilon >0$, by Chebyshev&rsquo;s inequality,</p><p>$$
P(|\bar{X}_n-\mu|>\epsilon) \le \frac{\sigma^2}{n\epsilon^2}.
$$</p><p>As $n\to\infty$, the right-hand side goes to 0, ans so must the left-hand side.</p><h2 id=references>References</h2><ol><li>Blitzstein, Joseph K, and Hwang, Jessica. &ldquo;Introduction to probability.&rdquo;</li></ol></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>Yychi</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>May 1, 2020</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=/tags/math/>math</a></div><nav class=post-nav><a class=prev href=/post/exponetial-distribution/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">Exponential Distribution</span>
<span class="prev-text nav-mobile">Prev</span></a>
<a class=next href=/post/vim%E5%91%BD%E4%BB%A4%E9%80%9F%E6%9F%A5/><span class="next-text nav-default">Vim Quick Reference</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div><script src=https://giscus.app/client.js data-repo=guyueshui/guyueshui.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkxNDI4MTY5NTE=" data-category=Ideas data-category-id=DIC_kwDOCIM2t84CW4nN data-mapping=title data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script></div></main><footer id=footer class=footer><div class=social-links><a href=mailto:guyueshui002@gmail.com class="iconfont icon-email" title=email></a>
<a href=https://github.com/guyueshui class="iconfont icon-github" title=github></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a></span><div class=busuanzi-footer></div><span class=copyright-year>&copy;
2018 -
2023<span class=heart><i class="iconfont icon-heart"></i></span><span>Yychi</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script>
<script type=text/javascript>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3.0.5/es5/tex-mml-chtml.js integrity="sha256-HGLuEfFcsUJGhvB8cQ8nr0gai9EucOOaIxFw7qxmd+w=" crossorigin=anonymous></script></body></html>