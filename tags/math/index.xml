<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Math on 水阙</title><link>https://guyueshui.github.io/tags/math/</link><description>Recent content in Math on 水阙</description><generator>Hugo</generator><language>en</language><lastBuildDate>Wed, 11 Sep 2024 14:57:54 +0800</lastBuildDate><atom:link href="https://guyueshui.github.io/tags/math/index.xml" rel="self" type="application/rss+xml"/><item><title>浅谈 Logistic 回归</title><link>https://guyueshui.github.io/post/%E6%B5%85%E8%B0%88-logistic-%E5%9B%9E%E5%BD%92/</link><pubDate>Fri, 15 Mar 2019 22:59:39 +0000</pubDate><guid>https://guyueshui.github.io/post/%E6%B5%85%E8%B0%88-logistic-%E5%9B%9E%E5%BD%92/</guid><description>&lt;p>In editing&amp;hellip;&lt;/p>
&lt;p>&lt;strong>Logistic 回归属于分类模型！！！&lt;/strong>&lt;/p>
&lt;h2 id="从最小二乘说起">从最小二乘说起&lt;/h2>
&lt;h2 id="线性回归">线性回归&lt;/h2>
&lt;h2 id="概率解释">概率解释&lt;/h2>
&lt;h2 id="sigmoid-函数的引入">Sigmoid 函数的引入&lt;/h2>
&lt;p>如果把我比作一张白纸，在我的知识储备中，现在只有线性回归。但是要处理分类问题，我该怎么办？没办法，先考虑一个二分类问题，$y \in {0,1}$，我们准备霸王硬上弓，用回归模型套上去！
$$
y = h_{\theta}(x)
$$&lt;/p></description></item><item><title>Matrix Factorization</title><link>https://guyueshui.github.io/post/matrix-factorization/</link><pubDate>Thu, 03 Jan 2019 21:07:38 +0000</pubDate><guid>https://guyueshui.github.io/post/matrix-factorization/</guid><description>&lt;h2 id="preliminaries">Preliminaries&lt;/h2>
&lt;p>&lt;strong>Def&lt;/strong>: A matrix $A \in M_n$ is &lt;em>normal&lt;/em> if $AA^∗ = A^∗A$, that is, if $A$ commutes with its conjugate transpose.&lt;/p>
&lt;p>&lt;strong>Def&lt;/strong>: A complex matrix $A$ is &lt;em>unitary&lt;/em> if $AA^∗ = I$ or $A^∗A = I$, and a real matrix $B$ is &lt;em>orthogonal&lt;/em> if $BB^T = I$ or $B^TB = I$.&lt;/p>
&lt;p>&lt;img src="https://i.loli.net/2019/01/03/5c2e1178ec116.png" alt="Image adapted from Meyer&amp;rsquo;s book">&lt;/p>
&lt;p>&lt;strong>There is no so-called &amp;ldquo;orthonormal&amp;rdquo; matrix. There is just an orthogonal matrix whose rows or columns are orthonormal vectors.&lt;/strong>&lt;/p></description></item><item><title>Exponential Distribution</title><link>https://guyueshui.github.io/post/exponetial-distribution/</link><pubDate>Tue, 25 Dec 2018 22:21:49 +0000</pubDate><guid>https://guyueshui.github.io/post/exponetial-distribution/</guid><description>&lt;h2 id="story">Story&lt;/h2>
&lt;blockquote>
&lt;p>The Exponential distribution is the continuous counterpart to the &lt;a href="file://./Geometric-Distribution.md">Geometric distribution&lt;/a>. The story of the Exponential distribution is analogous, but we are now waiting for a success in continuous time, where successes arrive at a rate of $\lambda$ successes per unit of time. The average number of successes in a time interval of length $t$ is $\lambda t$, though the actual number of successes varies randomly. An Exponential random variable represents the waiting time until the first arrival of a success.&lt;/p></description></item><item><title>常用结论的证明记录</title><link>https://guyueshui.github.io/post/%E4%B8%80%E4%BA%9B%E6%8E%A8%E5%AF%BC/</link><pubDate>Thu, 20 Dec 2018 19:18:29 +0000</pubDate><guid>https://guyueshui.github.io/post/%E4%B8%80%E4%BA%9B%E6%8E%A8%E5%AF%BC/</guid><description>&lt;h2 id="高斯分布的微分熵">高斯分布的微分熵&lt;/h2>
&lt;p>$X \sim \mathcal{N}(\mu, \sigma^2)~$，$\displaystyle f(x)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$，其微分熵推导过程如下：&lt;/p></description></item><item><title>最大熵对应的概率分布</title><link>https://guyueshui.github.io/post/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%AF%B9%E5%BA%94%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</link><pubDate>Wed, 01 Aug 2018 18:02:36 +0000</pubDate><guid>https://guyueshui.github.io/post/%E6%9C%80%E5%A4%A7%E7%86%B5%E5%AF%B9%E5%BA%94%E7%9A%84%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83/</guid><description>&lt;h2 id="最大熵定理">最大熵定理&lt;/h2>
&lt;p>&lt;em>设 $X \sim p(x)$ 是一个连续型随机变量，其微分熵定义为&lt;/em>
$$
h(X) = - \int p(x)\log p(x) dx
$$
&lt;em>其中，$\log$ 一般取自然对数 $\ln$, 单位为 奈特（nats）。&lt;/em>&lt;/p>
&lt;!-- more -->
&lt;p>考虑如下优化问题：
$$
\begin{array}{ll}
&amp;amp;\underset{p}{\text{Maximize}} &amp;amp; \displaystyle h(p) = - \int_S p(x)\log p(x) dx \newline
&amp;amp;\text{Subject to} &amp;amp;\displaystyle \int_S p(x) dx = 1 \newline
&amp;amp;~ &amp;amp; p(x) \ge 0 \newline
&amp;amp;~ &amp;amp; \displaystyle \int_S p(x) f_i(x) dx = \alpha_i, ~i=1,2,3,\dots,n
\end{array}
$$
其中，集合 $S$ 是随机变量的 support，即其所有可能的取值。我们意图找到这样的概率分布 $p$, 他满足所有的约束（前两条是概率公理的约束，最后一条叫做矩约束，在模型中有时会假设随机变量的矩为常数），并且能够使得熵最大。将上述优化问题写成标准形式：&lt;/p></description></item></channel></rss>